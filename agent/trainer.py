# -*- coding: utf-8 -*-
"""
Created on Mon Nov 10 14:46:05 2025

@author: chris and christine
"""

#!/usr/bin/env python3
"""
Optimized Trainer with Parallelism + Caching
=============================================

Complete trainer implementation with all performance optimizations:
- Parallel gradient computation (joblib/loky)
- Transport operator caching
- Optional Numba acceleration

Expected speedup on Ryzen 9 9900X: 10-20x

Author: Chris  - Performance Edition
Date: November 2025
"""

import numpy as np
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from pathlib import Path
import pickle
from retraction import retract_spd
from free_energy_clean import compute_total_free_energy, FreeEnergyBreakdown
from gradients.gradient_engine import compute_natural_gradients
from math_utils.transport_cache import add_cache_to_system, invalidate_cache_after_update
from gradients.gauge_fields import (retract_to_principal_ball)
from config import TrainingConfig
from data_utils.mu_tracking import create_mu_tracker, MuCenterTracking
from update_engine import GradientApplier


@dataclass
class TrainingHistory:
    """Container for training metrics over time."""
    
    steps: List[int] = field(default_factory=list)
    
    # Energy components
    total_energy: List[float] = field(default_factory=list)
    self_energy: List[float] = field(default_factory=list)
    belief_align: List[float] = field(default_factory=list)
    prior_align: List[float] = field(default_factory=list)
    observations: List[float] = field(default_factory=list)
    
    # Gradient norms (for diagnostics)
    grad_norm_mu_q: List[float] = field(default_factory=list)
    grad_norm_Sigma_q: List[float] = field(default_factory=list)
    grad_norm_phi: List[float] = field(default_factory=list)
    
    # Mu center tracking
    mu_tracker: Optional[MuCenterTracking] = None
    
# agent/trainer.py

    def record(self, step: int, energies,
               gradients: Optional[List] = None,
               system = None):
        """Record metrics for current step."""
        self.steps.append(step)
    
        # Energy components
        self.total_energy.append(energies.total)
        self.self_energy.append(energies.self_energy)
        self.belief_align.append(energies.belief_align)
        self.prior_align.append(energies.prior_align)
        self.observations.append(energies.observations)
    
        # Gradient norms (if provided)
        if gradients is not None:
            grad_mu_q_norm = np.mean([np.linalg.norm(g.delta_mu_q) for g in gradients])
            
            # ðŸ”¥ FIX: Use delta_L_q instead of delta_Sigma_q
            # Compute norm of Cholesky gradients (more meaningful than Sigma norms anyway!)
            grad_L_q_norm = np.mean([
                np.linalg.norm(g.delta_L_q) if g.delta_L_q is not None else 0.0
                for g in gradients
            ])
            
            grad_phi_norm = np.mean([np.linalg.norm(g.delta_phi) for g in gradients])
    
            self.grad_norm_mu_q.append(grad_mu_q_norm)
            self.grad_norm_Sigma_q.append(grad_L_q_norm)  # Still named Sigma for backward compat
            self.grad_norm_phi.append(grad_phi_norm)
    
        # Mu tracking
        if self.mu_tracker is None and system is not None:
            self.mu_tracker = create_mu_tracker(system)
    
        if self.mu_tracker is not None and system is not None:
            self.mu_tracker.record(step, system)


class Trainer:
    """
    Optimized training loop for multi-agent free energy minimization.
    
    Enhancements:
    - Parallel gradient computation (10-15x speedup)
    - Transport operator caching (2-3x speedup)
    - Performance monitoring and diagnostics
    """
    
    def __init__(self, system, config: Optional[TrainingConfig] = None):
        """
        Initialize optimized trainer.
        
        Args:
            system: MultiAgentSystem instance
            config: Training configuration (uses defaults if None)
        """
        self.system = system
        self.config = config or TrainingConfig()
        
        # Training state
        self.history = TrainingHistory()
        self.current_step = 0
        
        # Mu tracking
        self.history.mu_tracker = create_mu_tracker(system)
        
        # Early stopping
        self.best_energy = float('inf')
        self.patience_counter = 0
        
        # Checkpoint directory
        ckpt_dir = getattr(self.config, "checkpoint_dir", None)
        if ckpt_dir is not None:
            if isinstance(ckpt_dir, str):
                ckpt_dir = Path(ckpt_dir)
                self.config.checkpoint_dir = ckpt_dir
            if isinstance(ckpt_dir, Path):
                ckpt_dir.mkdir(parents=True, exist_ok=True)
        
        # ðŸš€ OPTIMIZATION: Add transport cache
        self.cache = add_cache_to_system(system, max_size=1000)
        print(f"âœ“ Transport cache initialized: {self.cache}")
        
        # Track performance
        self._step_times = []
    
    def step(self) -> FreeEnergyBreakdown:
        """
        Perform one optimization step with all optimizations.

        Returns:
            energies: Free energy breakdown after update
        """
        import time
        step_start = time.perf_counter()

        # (1) Compute free energy
        energies = compute_total_free_energy(self.system)

        # (2) ðŸš€ Compute natural gradients (PARALLEL + CACHED)
        gradients = compute_natural_gradients(self.system)

        # --- DEBUG PRINT: gradient magnitudes (Î¼, Î£, Ï†) ---
        self._debug_print_gradients(gradients)

        # (3) ðŸŽ¯ Apply updates using shared GradientApplier
        GradientApplier.apply_updates(self.system.agents, gradients, self.config)

        # (4) ðŸ”’ Re-enforce identical priors if in lock mode
        if getattr(self.system.config, "identical_priors", "off") == "lock":
            GradientApplier.apply_identical_priors_lock(self.system.agents)

        # (5) ðŸ—„ï¸ Invalidate cache after parameter updates
        invalidate_cache_after_update(self.system)

        # (6) Record history
        if self.config.save_history:
            self.history.record(self.current_step, energies, gradients, self.system)

        self.current_step += 1
        self._step_times.append(time.perf_counter() - step_start)

        return energies

    # NOTE: _update_agent() method removed - now using GradientApplier.apply_updates()
    # See update_engine.py for the shared update logic used by both Trainer and
    # HierarchicalEvolutionEngine.

    
    def train(self, n_steps: Optional[int] = None) -> TrainingHistory:
        """
        Run full training loop with performance monitoring.
        
        Args:
            n_steps: Override config.n_steps if provided
        
        Returns:
            history: Training history with all metrics
        """
        n_steps = n_steps or self.config.n_steps
        
        print("="*70)
        print("TRAINING MULTI-AGENT FREE ENERGY MINIMIZATION")
        print("="*70)
        print(f"System: {self.system.n_agents} agents")
        print(f"Steps: {n_steps}")
        #print(f"Learning rates: Î¼={self.config.lr_mu_q}, Î£={self.config.lr_sigma_q}, Ï†={self.config.lr_phi}")
        print(f"Optimizations: Parallel gradients + Transport caching")
        print("="*70)
        
        # Initial energy
        initial_energies = compute_total_free_energy(self.system)
        print(f"\nInitial energy: {initial_energies.total:.6f}")
        print(f"  Self: {initial_energies.self_energy:.6f}")
        print(f"  Belief align: {initial_energies.belief_align:.6f}")
        print(f"  Prior align: {initial_energies.prior_align:.6f}")
        print(f"  Observations: {initial_energies.observations:.6f}")
        print()
        
        # Training loop
        try:
            for step in range(n_steps):
                # One optimization step
                energies = self.step()
                
                # Logging
                if step % self.config.log_every == 0:
                    self._log_step(step, energies)
                
                # Checkpointing
                if (self.config.checkpoint_dir is not None and 
                    step % self.config.checkpoint_every == 0 and 
                    step > 0):
                    self._save_checkpoint(step)

                # Early stopping check
                if self.config.early_stop_threshold is not None:
                    if self._check_early_stop(energies.total):
                        print(f"\nâœ“ Early stopping at step {step}")
                        print(f"  No improvement for {self.patience_counter} steps")
                        break
        
        except KeyboardInterrupt:
            print("\nâš  Training interrupted by user")
        
        # Final summary with performance stats
        final_energies = compute_total_free_energy(self.system)
        avg_step_time = np.mean(self._step_times[-100:])  # Last 100 steps
        
        print("\n" + "="*70)
        print("TRAINING COMPLETE")
        print("="*70)
        print(f"Final energy: {final_energies.total:.6f}")
        print(f"Energy reduction: {initial_energies.total - final_energies.total:.6f}")
        print(f"Reduction %: {100*(initial_energies.total - final_energies.total)/initial_energies.total:.2f}%")
        print()
        print("Performance:")
        print(f"  Avg step time: {avg_step_time:.4f}s")
        print(f"  Steps/second: {1.0/avg_step_time:.2f}")
        if hasattr(self, 'cache'):
            print(f"  Cache stats: {self.cache.get_stats()}")
        print("="*70)
        
        return self.history
    
    def _log_step(self, step: int, energies: FreeEnergyBreakdown):
        """Print progress for current step with timing."""
        msg = f"Step {step:5d}: E = {energies.total:8.4f}"
        
        # Add component breakdown
        components = []
        if energies.self_energy > 1e-6:
            components.append(f"self={energies.self_energy:.3f}")
        if energies.belief_align > 1e-6:
            components.append(f"Î²={energies.belief_align:.3f}")
        if energies.prior_align > 1e-6:
            components.append(f"Î³={energies.prior_align:.3f}")
        if abs(energies.observations) > 1e-6:
            components.append(f"obs={energies.observations:.3f}")
        
        if components:
            msg += f"  [{', '.join(components)}]"
        
        # Add timing if available
        if self._step_times:
            recent_time = np.mean(self._step_times[-10:])
            msg += f"  ({recent_time:.3f}s/step)"
        
        print(msg)
    
    def _check_early_stop(self, current_energy: float) -> bool:
        """Check if training should stop early."""
        improvement = self.best_energy - current_energy
        
        if improvement > self.config.early_stop_threshold:
            self.best_energy = current_energy
            self.patience_counter = 0
            return False
        
        self.patience_counter += 1
        return self.patience_counter >= self.config.early_stop_patience
    
    def _save_checkpoint(self, step: int):
        """Save training checkpoint."""
        checkpoint_path = self.config.checkpoint_dir / f"checkpoint_step_{step}.pkl"
        
        checkpoint = {
            'step': step,
            'history': self.history,
            'config': self.config,
            'best_energy': self.best_energy,
            'patience_counter': self.patience_counter,
        }
        
        with open(checkpoint_path, 'wb') as f:
            pickle.dump(checkpoint, f)
        
        print(f"  ðŸ’¾ Saved checkpoint: {checkpoint_path.name}")

    # ------------------------------------------------------------
    # INTERNAL: Print gradient diagnostics for this step
    # ------------------------------------------------------------
    def _debug_print_gradients(self, gradients):
        """Print per-step gradient norms for Î¼, Î£, and Ï†."""
    
        # Î¼-gradient norms
        mu_norms = [
            np.linalg.norm(g.delta_mu_q) if g.delta_mu_q is not None else 0.0
            for g in gradients
        ]
    
        # --- Î£-gradient norms ---
        sigma_norms = []
        for g in gradients:
    
            # 1. If natural Î£-gradient exists, use that
            if hasattr(g, "delta_Sigma_natural") and g.delta_Sigma_natural is not None:
                sigma_norms.append(np.linalg.norm(g.delta_Sigma_natural))
    
            # 2. Else if Euclidean Î£-gradient exists, use that
            elif hasattr(g, "delta_Sigma_q") and g.delta_Sigma_q is not None:
                sigma_norms.append(np.linalg.norm(g.delta_Sigma_q))
    
            # 3. Else fallback: derive Î£-gradient from L-gradient
            elif hasattr(g, "delta_L_q") and g.delta_L_q is not None:
                # Î£-update: Î´Î£ â‰ˆ L Î´Láµ€ + Î´L Láµ€   (linearized)
                L = g.agent.L_q
                dL = g.delta_L_q
                dSigma = L @ dL.T + dL @ L.T
                sigma_norms.append(np.linalg.norm(dSigma))
    
            else:
                sigma_norms.append(0.0)
    
        # Ï†-gradient norms
        phi_norms = [
            np.linalg.norm(g.delta_phi) if g.delta_phi is not None else 0.0
            for g in gradients
        ]
        dL_norms = [np.linalg.norm(g.delta_L_q) if g.delta_L_q is not None else 0.0
            for g in gradients]
  
        print(
            f"\n [GRAD {self.current_step:05d}]\n  "
            f" Î¼: |mean={np.mean(mu_norms):.3e}  min={np.min(mu_norms):.3e}  max={np.max(mu_norms):.3e}  |\n  "
            f" L: |mean={np.mean(dL_norms):.3e}  min={np.min(dL_norms):.3e}  max={np.max(dL_norms):.3e}  |\n  "
            f" Î£: |mean={np.mean(sigma_norms):.3e}  min={np.min(sigma_norms):.3e}  max={np.max(sigma_norms):.3e}  |\n  "
            f" Ï†: |mean={np.mean(phi_norms):.3e}  min={np.min(phi_norms):.3e}  max={np.max(phi_norms):.3e}  |\n\n"
        )

